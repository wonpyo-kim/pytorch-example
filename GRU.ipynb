{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_cell(object):\n",
    "    def __init__(self, input_size, hidden_layer_size, target_size):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.target_size = target_size\n",
    "        \n",
    "        self.Wx = tf.Variable(tf.zeros([self.input_size, self.hidden_layer_size]))\n",
    "        self.Wr = tf.Variable(tf.zeros([self.input_size, self.hidden_layer_size]))\n",
    "        self.Wz = tf.Variable(tf.zeros([self.input_size, self.hidden_layer_size]))\n",
    "        \n",
    "        self.br = tf.Variable(tf.truncated_normal([self.hidden_layer_size], mean=1))\n",
    "        self.bz = tf.Variable(tf.truncated_normal([self.hidden_layer_size], mean=1))\n",
    "        \n",
    "        self.Wh = tf.Variable(tf.zeros([self.hidden_layer_size, self.hidden_layer_size]))\n",
    "        \n",
    "        self.Wo = tf.Variable(tf.truncated_normal([self.hidden_layer_size, self.target_size], mean=1, stddev=.01))\n",
    "        self.bo = tf.Variable(tf.truncated_normal([self.target_size], mean=1, stddev=.01))\n",
    "        self._inputs = tf.placeholder(tf.float32, shape=[None, None, self.input_size], name=\"inputs\")\n",
    "        \n",
    "        self.processed_input = process_batch_input_for_RNN(self._inputs)\n",
    "        \n",
    "        self.initial_hidden = self._inputs[:, 0, :]\n",
    "        self.initial_hidden = tf.matmul(self.initial_hidden, tf.zeros([input_size, hidden_layer_size]))\n",
    "    \n",
    "    def GRU(self, previous_hidden_state, x):\n",
    "        z = tf.sigmoid(tf.matmul(x, self.Wz) + self.bz)\n",
    "        r = tf.sigmoid(tf.matmul(x, self.Wr) + self.br)\n",
    "        \n",
    "        h_ = tf.tanh(tf.matmul(x, self.Wx) + tf.matmul(previous_hidden_state, self.Wh) * r)\n",
    "        \n",
    "        current_hidden_state = tf.multiply((1-z), h_) + tf.multiply(previous_hidden_state, z)\n",
    "        return current_hidden_state\n",
    "    \n",
    "    def get_states(self):\n",
    "        all_hidden_states = tf.scan(self.GRU,\n",
    "                                    self.processed_input,\n",
    "                                    initializer=self.initial_hidden,\n",
    "                                    name=\"states\")\n",
    "        return all_hidden_states\n",
    "    \n",
    "    def get_output(self, hidden_state):\n",
    "        output = tf.nn.relu(tf.matmul(hidden_state, self.Wo) + self.bo)\n",
    "        return output\n",
    "    \n",
    "    def get_outputs(self):\n",
    "        all_hidden_states = self.get_states()\n",
    "        all_outputs = tf.map_fn(self.get_output, all_hidden_states)\n",
    "        return all_outputs\n",
    "\n",
    "def process_batch_input_for_RNN(batch_input):\n",
    "    batch_input_ = tf.transpose(batch_input, perm=[2, 0, 1])\n",
    "    X = tf.transpose(batch_input_)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_size = 30\n",
    "input_size = 8\n",
    "target_size = 10\n",
    "\n",
    "y = tf.placeholder(tf.float32, shape=[None, target_size], name=\"inputs\")\n",
    "\n",
    "rnn = RNN_cell(input_size, hidden_layer_size, target_size)\n",
    "\n",
    "outputs = rnn.get_outputs()\n",
    "\n",
    "last_output = outputs[-1]\n",
    "\n",
    "output = tf.nn.softmax(last_output)\n",
    "\n",
    "cross_entropy = -tf.reduce_sum(y * tf.log(output))\n",
    "\n",
    "train_step = tf.train.AdamOptimizer().minimize(cross_entropy)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(output, 1))\n",
    "accuracy = (tf.reduce_mean(tf.cast(correct_prediction, tf.float32))) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loss: 228.765 \t tr_acc: 22.3571 \t ts_acc: 20.202\n",
      "2 loss: 222.952 \t tr_acc: 27.0 \t ts_acc: 26.0101\n",
      "3 loss: 209.629 \t tr_acc: 47.3571 \t ts_acc: 43.6869\n",
      "4 loss: 189.739 \t tr_acc: 52.2857 \t ts_acc: 51.0101\n",
      "5 loss: 169.972 \t tr_acc: 51.7857 \t ts_acc: 51.0101\n",
      "6 loss: 152.825 \t tr_acc: 55.7143 \t ts_acc: 54.0404\n",
      "7 loss: 138.068 \t tr_acc: 61.5714 \t ts_acc: 59.596\n",
      "8 loss: 124.75 \t tr_acc: 64.2143 \t ts_acc: 62.6263\n",
      "9 loss: 112.763 \t tr_acc: 67.5714 \t ts_acc: 66.1616\n",
      "10 loss: 102.034 \t tr_acc: 68.8571 \t ts_acc: 67.6768\n",
      "11 loss: 92.3516 \t tr_acc: 70.2857 \t ts_acc: 68.9394\n",
      "12 loss: 83.6129 \t tr_acc: 72.0714 \t ts_acc: 69.9495\n",
      "13 loss: 75.8086 \t tr_acc: 74.2857 \t ts_acc: 70.9596\n",
      "14 loss: 68.8952 \t tr_acc: 76.7857 \t ts_acc: 73.2323\n",
      "15 loss: 62.7923 \t tr_acc: 78.8571 \t ts_acc: 75.5051\n",
      "16 loss: 57.4139 \t tr_acc: 80.2857 \t ts_acc: 76.2626\n",
      "17 loss: 52.6989 \t tr_acc: 81.5714 \t ts_acc: 78.2828\n",
      "18 loss: 48.5951 \t tr_acc: 82.6429 \t ts_acc: 79.5455\n",
      "19 loss: 45.0632 \t tr_acc: 83.7143 \t ts_acc: 80.0505\n",
      "20 loss: 42.0539 \t tr_acc: 84.9286 \t ts_acc: 81.3131\n",
      "21 loss: 39.46 \t tr_acc: 85.2143 \t ts_acc: 82.3232\n",
      "22 loss: 37.1684 \t tr_acc: 85.8571 \t ts_acc: 83.0808\n",
      "23 loss: 35.1162 \t tr_acc: 86.5714 \t ts_acc: 84.0909\n",
      "24 loss: 33.2701 \t tr_acc: 87.2143 \t ts_acc: 84.596\n",
      "25 loss: 31.618 \t tr_acc: 87.8571 \t ts_acc: 84.8485\n",
      "26 loss: 30.1257 \t tr_acc: 88.4286 \t ts_acc: 85.3535\n",
      "27 loss: 28.7555 \t tr_acc: 89.4286 \t ts_acc: 85.8586\n",
      "28 loss: 27.4706 \t tr_acc: 89.9286 \t ts_acc: 86.3636\n",
      "29 loss: 26.246 \t tr_acc: 90.4286 \t ts_acc: 86.6162\n",
      "30 loss: 25.0643 \t tr_acc: 90.9286 \t ts_acc: 88.1313\n",
      "31 loss: 23.914 \t tr_acc: 91.0 \t ts_acc: 89.1414\n",
      "32 loss: 22.7902 \t tr_acc: 91.3571 \t ts_acc: 89.3939\n",
      "33 loss: 21.6894 \t tr_acc: 91.7857 \t ts_acc: 89.899\n",
      "34 loss: 20.6076 \t tr_acc: 92.0714 \t ts_acc: 90.1515\n",
      "35 loss: 19.5432 \t tr_acc: 92.2857 \t ts_acc: 90.1515\n",
      "36 loss: 18.5067 \t tr_acc: 92.7143 \t ts_acc: 90.404\n",
      "37 loss: 17.512 \t tr_acc: 93.0 \t ts_acc: 90.404\n",
      "38 loss: 16.5736 \t tr_acc: 93.3571 \t ts_acc: 90.6566\n",
      "39 loss: 15.7014 \t tr_acc: 93.7857 \t ts_acc: 90.9091\n",
      "40 loss: 14.8955 \t tr_acc: 93.9286 \t ts_acc: 91.1616\n",
      "41 loss: 14.1519 \t tr_acc: 94.0714 \t ts_acc: 91.4141\n",
      "42 loss: 13.4696 \t tr_acc: 94.4286 \t ts_acc: 91.4141\n",
      "43 loss: 12.8569 \t tr_acc: 94.5714 \t ts_acc: 91.9192\n",
      "44 loss: 12.3336 \t tr_acc: 95.0 \t ts_acc: 92.1717\n",
      "45 loss: 11.9106 \t tr_acc: 95.0 \t ts_acc: 92.1717\n",
      "46 loss: 11.5556 \t tr_acc: 94.9286 \t ts_acc: 92.1717\n",
      "47 loss: 11.1929 \t tr_acc: 95.5 \t ts_acc: 92.1717\n",
      "48 loss: 10.7463 \t tr_acc: 95.7857 \t ts_acc: 92.1717\n",
      "49 loss: 10.2174 \t tr_acc: 95.9286 \t ts_acc: 91.9192\n",
      "50 loss: 9.68699 \t tr_acc: 96.0714 \t ts_acc: 91.9192\n",
      "51 loss: 9.21677 \t tr_acc: 96.5 \t ts_acc: 91.6667\n",
      "52 loss: 8.817 \t tr_acc: 96.6429 \t ts_acc: 91.9192\n",
      "53 loss: 8.47588 \t tr_acc: 96.8571 \t ts_acc: 91.6667\n",
      "54 loss: 8.17811 \t tr_acc: 97.0 \t ts_acc: 91.9192\n",
      "55 loss: 7.90555 \t tr_acc: 97.0714 \t ts_acc: 91.9192\n",
      "56 loss: 7.64409 \t tr_acc: 97.2143 \t ts_acc: 92.1717\n",
      "57 loss: 7.38621 \t tr_acc: 97.4286 \t ts_acc: 92.4242\n",
      "58 loss: 7.12966 \t tr_acc: 97.7143 \t ts_acc: 92.4242\n",
      "59 loss: 6.87521 \t tr_acc: 97.7857 \t ts_acc: 92.4242\n",
      "60 loss: 6.62624 \t tr_acc: 97.7857 \t ts_acc: 92.4242\n",
      "61 loss: 6.38537 \t tr_acc: 97.8571 \t ts_acc: 92.4242\n",
      "62 loss: 6.15642 \t tr_acc: 98.0714 \t ts_acc: 92.6768\n",
      "63 loss: 5.94157 \t tr_acc: 98.4286 \t ts_acc: 92.6768\n",
      "64 loss: 5.74149 \t tr_acc: 98.5 \t ts_acc: 92.9293\n",
      "65 loss: 5.55249 \t tr_acc: 98.7143 \t ts_acc: 92.9293\n",
      "66 loss: 5.37112 \t tr_acc: 98.7143 \t ts_acc: 93.1818\n",
      "67 loss: 5.19665 \t tr_acc: 98.7143 \t ts_acc: 93.1818\n",
      "68 loss: 5.02523 \t tr_acc: 98.7857 \t ts_acc: 93.4343\n",
      "69 loss: 4.85679 \t tr_acc: 98.8571 \t ts_acc: 93.4343\n",
      "70 loss: 4.69048 \t tr_acc: 98.9286 \t ts_acc: 93.4343\n",
      "71 loss: 4.52496 \t tr_acc: 98.9286 \t ts_acc: 93.4343\n",
      "72 loss: 4.36338 \t tr_acc: 98.9286 \t ts_acc: 93.4343\n",
      "73 loss: 4.20402 \t tr_acc: 98.9286 \t ts_acc: 93.6869\n",
      "74 loss: 4.05103 \t tr_acc: 98.9286 \t ts_acc: 93.6869\n",
      "75 loss: 3.90802 \t tr_acc: 99.0714 \t ts_acc: 93.6869\n",
      "76 loss: 3.77517 \t tr_acc: 99.0714 \t ts_acc: 93.9394\n",
      "77 loss: 3.64989 \t tr_acc: 99.0714 \t ts_acc: 93.9394\n",
      "78 loss: 3.52938 \t tr_acc: 99.0714 \t ts_acc: 93.9394\n",
      "79 loss: 3.41358 \t tr_acc: 99.0714 \t ts_acc: 94.1919\n",
      "80 loss: 3.30564 \t tr_acc: 99.1429 \t ts_acc: 94.1919\n",
      "81 loss: 3.21124 \t tr_acc: 99.2143 \t ts_acc: 94.1919\n",
      "82 loss: 3.13408 \t tr_acc: 99.2857 \t ts_acc: 94.1919\n",
      "83 loss: 3.06732 \t tr_acc: 99.3571 \t ts_acc: 93.9394\n",
      "84 loss: 2.99718 \t tr_acc: 99.4286 \t ts_acc: 93.9394\n",
      "85 loss: 2.91688 \t tr_acc: 99.4286 \t ts_acc: 94.1919\n",
      "86 loss: 2.82728 \t tr_acc: 99.4286 \t ts_acc: 93.9394\n",
      "87 loss: 2.73176 \t tr_acc: 99.5 \t ts_acc: 94.1919\n",
      "88 loss: 2.6352 \t tr_acc: 99.5 \t ts_acc: 94.1919\n",
      "89 loss: 2.54101 \t tr_acc: 99.5 \t ts_acc: 94.4444\n",
      "90 loss: 2.45022 \t tr_acc: 99.5714 \t ts_acc: 94.4444\n",
      "91 loss: 2.36389 \t tr_acc: 99.5714 \t ts_acc: 94.4444\n",
      "92 loss: 2.28334 \t tr_acc: 99.5714 \t ts_acc: 94.1919\n",
      "93 loss: 2.20979 \t tr_acc: 99.5714 \t ts_acc: 94.1919\n",
      "94 loss: 2.14413 \t tr_acc: 99.6429 \t ts_acc: 94.1919\n",
      "95 loss: 2.08814 \t tr_acc: 99.7143 \t ts_acc: 93.9394\n",
      "96 loss: 2.0414 \t tr_acc: 99.7143 \t ts_acc: 94.1919\n",
      "97 loss: 2.00233 \t tr_acc: 99.7857 \t ts_acc: 94.1919\n",
      "98 loss: 1.96745 \t tr_acc: 99.7857 \t ts_acc: 93.9394\n",
      "99 loss: 1.93149 \t tr_acc: 99.7857 \t ts_acc: 93.9394\n",
      "100 loss: 1.89073 \t tr_acc: 99.7857 \t ts_acc: 93.9394\n",
      "101 loss: 1.84739 \t tr_acc: 99.7857 \t ts_acc: 93.6869\n",
      "102 loss: 1.80584 \t tr_acc: 99.7857 \t ts_acc: 93.9394\n",
      "103 loss: 1.77163 \t tr_acc: 99.7857 \t ts_acc: 94.4444\n",
      "104 loss: 1.74764 \t tr_acc: 99.7857 \t ts_acc: 94.1919\n",
      "105 loss: 1.73555 \t tr_acc: 99.7857 \t ts_acc: 94.4444\n",
      "106 loss: 1.73198 \t tr_acc: 99.7143 \t ts_acc: 94.4444\n",
      "107 loss: 1.71652 \t tr_acc: 99.7143 \t ts_acc: 94.4444\n",
      "108 loss: 1.67916 \t tr_acc: 99.7143 \t ts_acc: 94.4444\n",
      "109 loss: 1.63366 \t tr_acc: 99.7143 \t ts_acc: 94.4444\n",
      "110 loss: 1.59581 \t tr_acc: 99.7143 \t ts_acc: 94.697\n",
      "111 loss: 1.56318 \t tr_acc: 99.7143 \t ts_acc: 94.9495\n",
      "112 loss: 1.51325 \t tr_acc: 99.7857 \t ts_acc: 95.202\n",
      "113 loss: 1.53887 \t tr_acc: 99.7857 \t ts_acc: 95.202\n",
      "114 loss: 1.46025 \t tr_acc: 99.7857 \t ts_acc: 95.4545\n"
     ]
    }
   ],
   "source": [
    "# data preperation\n",
    "def get_on_hot(number):\n",
    "    on_hot = [0] * 10\n",
    "    on_hot[number] = 1\n",
    "    return on_hot\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "X = digits.images\n",
    "Y_ = digits.target\n",
    "#Y = map(get_on_hot, Y_)\n",
    "\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "Y = sess.run(tf.one_hot(indices=Y_, depth=target_size))\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.22, random_state=42)\n",
    "X_train = X_train[:1400]\n",
    "y_train = y_train[:1400]\n",
    "\n",
    "\n",
    "sess.run(tf.initialize_all_variables())\n",
    "for epoch in range(200):\n",
    "    start, end = 0, 100\n",
    "    for i in range(14):\n",
    "        X = X_train[start:end]\n",
    "        Y = y_train[start:end]\n",
    "        start = end\n",
    "        end = start + 100\n",
    "        sess.run(train_step, feed_dict={rnn._inputs: X, y: Y})\n",
    "    \n",
    "    Loss = str(sess.run(cross_entropy, feed_dict={rnn._inputs: X, y: Y}))\n",
    "    Train_accuracy = str(sess.run(accuracy, feed_dict={rnn._inputs: X_train, y: y_train}))\n",
    "    Test_accuracy = str(sess.run(accuracy, feed_dict={rnn._inputs: X_test, y: y_test}))\n",
    "    \n",
    "    print(\"{} loss: {} \\t tr_acc: {} \\t ts_acc: {}\".format((epoch+1), Loss, Train_accuracy, Test_accuracy))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
